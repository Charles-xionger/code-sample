# Stream 流

[官方链接](http://nodejs.cn/api/stream.html#stream)

官方介绍： 流是用于在 Node.js 中处理流数据的抽象接口。 stream 模块提供了用于实现流接口的 API。

在构建较复杂的系统时，通常将其拆解为功能独⽴立的若⼲干部分。这些部分的接⼝口遵循⼀一定的规
范，通过某种⽅方式相连，以共同完成较复杂的任务。譬如，shell通过管道|连接各部分，其输
⼊入输出的规范是⽂文本流。

在Node.js中，内置的Stream模块也实现了了类似功能，各部分通过.pipe()连接。

## Node.js 中有四种基本的流类型：

Writable: 可以写入数据的流（例如，fs.createWriteStream()）。
Readable: 可以从中读取数据的流（例如，fs.createReadStream()）。
Duplex: Readable 和 Writable 的流（例如，net.Socket）。 duplex: adj: 双重的，两倍的
Transform: 可以在写入和读取数据时修改或转换数据的 Duplex 流（例如，zlib.createDeflate()）。

此外，此模块还包括实用函数 stream.pipeline()、stream.finished()、stream.Readable.from() 和 stream.addAbortSignal()。

```js
var Stream = require('stream')
var Readable = Stream.Readable
var Writable = Stream.Writable
var Duplex = Stream.Duplex
var Transform = Stream.Transform
```

## Readable
```js
/** Readable 创建可读流*/

// 实例：流式消耗迭代器器中的数据。 对象数组一类可以迭代的数据
const Readable = require('stream').Readable

class ToReadable extends Readable {
  constructor(iterator) {
    super()
    this.iterator = iterator
  }

  // 子类需要实现该方法
  // 这是生产数据的逻辑
  _read () {
    const res = this.iterator.next()
    if (res.done) {
      // 当前迭代结束
      // 数据源已经消耗完了，调用`push(null)`通知流
      return this.push(null)
    }
    // 避免同步输出太多的任务，使用异步
    setTimeout(() => {
      // 通过`push`方法将数据添加到流中
      this.push(res.value + '\n')
    }, 0)
  }
}
const iterator = function (limit) {
  return {
    next: function () {
      // 当limit 是否消耗完
      if (limit--) {
        return { done: false, value: limit + Math.random() }
      }
      return { done: true }
    }
  }
}(10000)

const readable = new ToReadable(iterator)

// 输入数据 readable.on()
// 监听`data`事件，一次获取一个数据
readable.on('data', data => process.stdout.write(data))

// 迭代结束 监听end事件
// 所有流式的数据均已读完
readable.on('end', () => process.stdout.write('DONE'))
```
执行上述代码,源源不断的将10000个随机数写进标准输出流。
1. 创建可读流时，需要继承Readable，并实现_read方法。 
* _read方法是从底层系统读取具体数据的逻辑，即生产数据的逻辑。 
* 在_read方法中，通过调用push(data)将数据放入可读流中供下游消耗。 
* 在_read方法中，可以同步调用push(data)，也可以异步调用。 
* 当全部数据都生产出来后，必须调用push(null)来结束可读流。 
* 流一旦结束，便不能再调用push(data)添加数据。

2. 可以通过监听data事件的方式消耗可读流。 
* 在首次监听其data事件后，readable便会持续不断地调用_read()方法，通过触发data事件将数据输出。 
* 第一次data事件会在下一个tick中触发，所以，可以安全地将数据输出前的逻辑放在事件监听后（同一个tick中）。 
* 当数据全部被消耗时，会触发end事件。

## Writable
创建可写流。

前面通过继承的方式去创建一类可读流，这种方法也适用于创建一类可写流，只是需要实现的是_write(data, enc, next)方法，而不是_read()方法。

有些简单的情况下不需要创建一类流，而只是一个流对象，可以用如下方式去做：

```js
const Writable = require('stream').Writable

const writable = Writable()
// 实现`_write`方法
// 这是将数据写入底层的逻辑
writable._write = function (data, enc, next) {
  // 将流中的数据写入底层
    // 此处传入数据为什么需要toString()?
  process.stdout.write(data.toString().toUpperCase())
  // 写入完成时，调用`next()`方法通知流传入下一个数据
  process.nextTick(next)
}

// 所有数据均已写入底层
writable.on('finish', () => process.stdout.write('DONE'))

// 将一个数据写入流中
writable.write('a' + '\n')
writable.write('b' + '\n')
writable.write('c' + '\n')

// 再无数据写入流时，需要调用`end`方法
writable.end()
```

* 上游通过调用writable.write(data)将数据写入可写流中。write()方法会调用_write()将data写入底层。
* 在_write中，当数据成功写入底层后，必须调用next(err)告诉流开始处理下一个数据。
* next的调用既可以是同步的，也可以是异步的。
* 上游必须调用writable.end(data)来结束可写流，data是可选的。此后，不能再调用write新增数据。
* 在end方法调用后，当所有底层的写操作均完成时，会触发finish事件。

上⾯面的例子中，process.stdout代表标准输出流，实际是⼀个可读写的stream(流)。

## Duplex
创建可读写流
```js
var Duplex = require('stream').Duplex

var duplex = Duplex()

// 重写 _read 和 _write 两个方法
// 可读端底层读取逻辑
duplex._read = function () {
  this._readNum = this._readNum || 0
  if (this._readNum > 1) {
    // 当数据大于1 时
    this.push(null) // 终止 
  } else {
    this.push('' + (this._readNum++))
  }
}

// 可写端底层写逻辑
duplex._write = function (buf, enc, next) {
  // a, b
  process.stdout.write('_write ' + buf.toString() + '\n')
  next()
}

// 0, 1
duplex.on('data', data => console.log('ondata', data.toString()))

duplex.write('a')
duplex.write('b')
duplex.write('x')

duplex.end()
```
上⾯面的代码中实现了read⽅方法，所以可以监听data事件来消耗Duplex产⽣的数据。 同时，又
实现了write⽅法，可作为下游去消耗数据。

因为它既可读⼜又可写，所以称它有两端：可写端和可读端。 

可写端的接⼝口与Writable⼀一致，作为下游来使⽤用；

可读端的接⼝口与Readable⼀一致，作为上游来使⽤用。

## Transfrom

在 Duplex 的实现例子最后结果：可读流中的数据（0, 1）与可写流中的数据（’a’, ‘b’）是隔离开的。

在 Transfrom 中可写端写入的数据变换后会自动添加到可读端。

Transfrom继承自 Duplex ，自己实现了 __write 和 __read , 同时要求用户实现一个__transfromm 的方法。

## 数据类型

调用：data.toString()。

在 shell 中，用管道连接上下游，上游和下游输出的都是标准的文本流。

在node中：

可读流： push(data) data: String | Buffer, 消耗数据的时候。data实际上输出的数据都是 Buffer类型

可写流： write(data) data: String | Buffer, __write(data) 调用时传入的data 都是Buffer类型

node中 steam 的默认情况下都是 Buffer类型。

但每个构造函数都接收⼀个配置对象，有⼀个objectMode的选项。

```js
const Readable = require('stream').Readable
const readable = Readable()
readable.push('a')
readable.push('b')
readable.push(null)
readable.on('data', data => console.log(data))

// 输出结果： <Buffer 61> <Buffer 62>
```
Readable设置objectMode后：

```js
const Readable = require('stream').Readable
const readable = Readable({
  objectMode: true
})
readable.push('a')
readable.push('b')
readable.push({})
readable.push(null)
readable.on('data', data => console.log(data))

// 输出结果可以是其他类型：
// a
// b
// {}
```
